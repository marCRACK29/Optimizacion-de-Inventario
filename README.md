# Optimizaci贸n de Inventario 

> **Proyecto Final de Inteligencia Artificial** > Aplicaci贸n de t茅cnicas de Aprendizaje por Refuerzo (Reinforcement Learning) para la gesti贸n eficiente de inventarios.

##  Descripci贸n

Este proyecto aborda el problema de la **optimizaci贸n de inventarios** utilizando algoritmos de Inteligencia Artificial. El objetivo principal es encontrar una pol铆tica 贸ptima de reposici贸n que minimice los costos asociados (almacenamiento, pedidos y fallas de stock) mientras se maximiza el nivel de inventario.

El sistema utiliza algoritmos de **Reinforcement Learning (RL)** (como DQN) implementados con *Stable Baselines3* y *Gymnasium*. 

##  Metodolog铆a y Datos

El proyecto se basa en el dataset `retail_store_inventory.csv`. Tras realizar un **An谩lisis Exploratorio de Datos (EDA)**, se tomaron las siguientes decisiones de dise帽o para el entrenamiento:

* **Enfoque en Producto nico (P0001):** Se detect贸 que el comportamiento de precios y demanda del producto `P0001` era consistente entre las diferentes tiendas.
* **Simulaci贸n de Historial Extendido:** Para reducir la complejidad y aumentar los datos disponibles para el agente, se filtraron los datos de `P0001` y se concatenaron las series temporales de las 5 tiendas (S001-S005). Esto genera una "super-tienda" con un historial secuencial extenso para el entrenamiento.
* **Variables de Estado (Observaci贸n):** El agente toma decisiones bas谩ndose en:
    * Nivel de Inventario   
    * Precio y Descuento
    * Precios de la competencia
    * Factores externos: Clima, Festivos y Estacionalidad.
    * Categor铆a del producto

##  Autores

Desarrollado por:
* **Mat铆as Figueroa**
* **Gabriel Castillo**
* **Daniel T谩maro**
* **Marcos Mart铆nez**

##  Estructura del Proyecto

El repositorio est谩 organizado de la siguiente manera:

| Carpeta/Archivo | Descripci贸n |
|-----------------|-------------|
| ` configs/` | Archivos de configuraci贸n e hiperpar谩metros para el entrenamiento. |
| ` data/` | Conjuntos de datos utilizados para la simulaci贸n y validaci贸n. |
| ` notebooks/` | Jupyter Notebooks con an谩lisis exploratorio, entrenamiento y experimentos. |
| ` src/` | C贸digo fuente del entorno (`Gymnasium`) y l贸gica del negocio. |
| ` requirements.txt` | Lista de dependencias y librer铆as necesarias. |

## 锔 Instalaci贸n

Sigue estos pasos para configurar el entorno de desarrollo local:

1. **Clonar el repositorio:**
   ```bash
   git clone git@github.com:marCRACK29/Optimizacion-de-Inventario.git
   cd Optimizacion-de-Inventario
   ```

2. **Crear un entorno virtual:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Linux/Mac
   .\venv\Scripts\activate  # En Windows
   ```

3. **Instalar las dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

##  Uso

La ejecuci贸n principal del proyecto se realiza a trav茅s de de los cuadernos de Jupyter Notebooks. Para iniciar: 

1. **Abre tu editor de c贸digo:**
   ```bash
   # opciones
   code . # para Visual Studio Code
   antigravity . 
   cursor . 
   ```

2. **Navega a la carpeta ` notebooks/`.**

3. **Ejecuta el notebook `training_dqn.ipynb` para entrenar el agente.**

4. **Ejecutar los otros notebooks para analizar los resultados.**
    - `EDA.ipynb`: (Opcional) Visualiza la limpieza y preparaci贸n de los datos. Genera los archivos de entrenamiento.
    - `sanity_cheks.ipynb`
    - `benchmarking.ipynb` 
    - `train_test_split.ipynb`
    - `visualizar_episodio.ipynb`

##  Tecnolog铆as Utilizadas

- **Python 3.12**
- **Stable Baselines3**: Algoritmos de RL.
- **Gymnasium (OpenAI Gym)**: Creaci贸n del entorno de simulaci贸n.
- **Pandas & NumPy**: Procesamiento de datos.
- **Matplotlib**: Visualizaci贸n de resultados.